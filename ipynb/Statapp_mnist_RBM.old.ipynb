{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Statapp 2015 : Apprentissage MNIST"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Commen\u00e7ons par importer la base, peut-\u00eatre il vaudrait mieux l'enregistrer sur le serveur, parce que le download est un peu long !\n",
      "\n",
      "(Pour faire \u00e7a plus facilement: http://scikit-learn.org/stable/datasets/#downloading-datasets-from-the-mldata-org-repository)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import time\n",
      "t = time.time()\n",
      "url = 'http://deeplearning.net/data/mnist/mnist.pkl.gz'\n",
      "\n",
      "try : \n",
      "    print ('Try')\n",
      "    import gzip\n",
      "    mnist_dataset = gzip.open(os.path.basename(url), 'rb')\n",
      "\n",
      "    import pickle\n",
      "    u = pickle.Unpickler(mnist_dataset)\n",
      "    u.encoding = 'latin1'\n",
      "    train_set, valid_set, test_set = u.load()\n",
      "\n",
      "    def shared_dataset(data_xy):\n",
      "\n",
      "        data_x, data_y = data_xy\n",
      "        return data_x, data_y\n",
      "\n",
      "    test_set_x, test_set_y = shared_dataset(test_set)\n",
      "    valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
      "    train_set_x, train_set_y = shared_dataset(train_set)\n",
      "    \n",
      "except :\n",
      "    print ('Except')\n",
      "\n",
      "    import urllib2\n",
      "    req = urllib2.urlopen (url)\n",
      "    print(\"downloading \" + url)\n",
      "    \n",
      "    import os\n",
      "    with open(os.path.basename(url), \"wb\") as local_file:\n",
      "            local_file.write(req.read())\n",
      "    \n",
      "    import gzip\n",
      "    mnist_dataset = gzip.open(os.path.basename(url), 'rb')\n",
      "\n",
      "    import pickle\n",
      "    u = pickle.Unpickler(mnist_dataset)\n",
      "    u.encoding = 'latin1'\n",
      "    train_set, valid_set, test_set = u.load()\n",
      "\n",
      "    def shared_dataset(data_xy):\n",
      "\n",
      "        data_x, data_y = data_xy\n",
      "        return data_x, data_y\n",
      "\n",
      "    test_set_x, test_set_y = shared_dataset(test_set)\n",
      "    valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
      "    train_set_x, train_set_y = shared_dataset(train_set)\n",
      "\n",
      "print (time.time() - t) #3.77 s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Regression logistique multinomiale"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "t= time.time()\n",
      "\n",
      "print(t)\n",
      "import numpy as np\n",
      "#from sklearn import datasets\n",
      "from sklearn import svm\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn import linear_model\n",
      "import scipy\n",
      "a = 0.01\n",
      "b = 0.5\n",
      "i = 0\n",
      "score_passe = 0\n",
      "score_present = 0.01\n",
      "while i<2 and score_passe <= score_present:\n",
      "    possible_parameters = np.linspace(a,b,10)\n",
      "    print(possible_parameters)\n",
      "\n",
      "    clf_rlm = grid_search.GridSearchCV(\n",
      "        linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, \n",
      "        fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None),\n",
      "        {'C': possible_parameters},\n",
      "        cv=3,\n",
      "        scoring='accuracy',\n",
      "        refit=True\n",
      "    )\n",
      "\n",
      "    print (time.time()-t) #4min for one iteration #On the new server 308s\n",
      "    clf_rlm.fit(train_set_x, train_set_y)\n",
      "    print(\"meilleur estimateur : \", clf_rlm.best_estimator_)\n",
      "    score_passe=score_present\n",
      "    score_present = metrics.accuracy_score(test_set_y, clf_rlm.predict(test_set_x))\n",
      "    print(\"meilleur parametre : \", clf_rlm.best_params_)\n",
      "    print(\"score : \", clf_rlm.scorer_)\n",
      "    print (\"final score: \", score_present)\n",
      "    \n",
      "    if clf_rlm.best_params_['C'] == a:\n",
      "        c = a - (b-a)/2\n",
      "        b = a\n",
      "        a = max(0.001,c)\n",
      "    elif clf_rlm.best_params_['C'] == b:\n",
      "        c = b + (b-a)/2\n",
      "        a = b\n",
      "        b = min(1,c)\n",
      "    else:\n",
      "        a = (a + clf_rlm.best_params_['C'])/2\n",
      "        b = (b + clf_rlm.best_params_['C'])/2\n",
      "\n",
      "    i=i+1\n",
      "\n",
      "print(\"fin de la boucle\")\n",
      "print(\"meilleur estimateur : \", clf_rlm.best_estimator_)\n",
      "print(\"meilleur parametre : \", clf_rlm.best_params_)\n",
      "print(\"score : \", clf_rlm.scorer_)\n",
      "print (\"final score: \", score_present)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "'''1424698747.74\n",
      "[ 0.01        0.06444444  0.11888889  0.17333333  0.22777778  0.28222222\n",
      "  0.33666667  0.39111111  0.44555556  0.5       ]\n",
      "0.0221090316772\n",
      "('meilleur estimateur : ', LogisticRegression(C=0.33666666666666667, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
      "          random_state=None, tol=0.0001))\n",
      "('meilleur parametre : ', {'C': 0.33666666666666667})\n",
      "('score : ', make_scorer(accuracy_score))\n",
      "('final score: ', 0.92059999999999997)\n",
      "[ 0.17333333  0.20055556  0.22777778  0.255       0.28222222  0.30944444\n",
      "  0.33666667  0.36388889  0.39111111  0.41833333]\n",
      "1942.24499321\n",
      "('meilleur estimateur : ', LogisticRegression(C=0.30944444444444441, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
      "          random_state=None, tol=0.0001))\n",
      "('meilleur parametre : ', {'C': 0.30944444444444441})\n",
      "('score : ', make_scorer(accuracy_score))\n",
      "('final score: ', 0.92069999999999996)\n",
      "fin de la boucle\n",
      "('meilleur estimateur : ', LogisticRegression(C=0.30944444444444441, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
      "          random_state=None, tol=0.0001))\n",
      "('meilleur parametre : ', {'C': 0.30944444444444441})\n",
      "('score : ', make_scorer(accuracy_score))\n",
      "('final score: ', 0.92069999999999996)''''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_set_y_rlm = clf_rlm.fit(train_set_x, train_set_y).predict(test_set_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "\n",
      "\n",
      "from sklearn.metrics import confusion_matrix\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "cm = confusion_matrix(test_set_y, pred_set_y_rlm)\n",
      "\n",
      "print(cm)\n",
      "\n",
      "cm_ = np.zeros((10,10), dtype=np.float)\n",
      "for i in range (0, len(cm)):\n",
      "    sum_list = sum(cm[i])\n",
      "    for j in range (0, len(cm[i])) :\n",
      "        cm_[i][j] = (1.0 * cm[i][j]/ sum_list)*1000\n",
      "    \n",
      "print(cm_)\n",
      "    \n",
      "# Show confusion matrix in a separate window\n",
      "plt.matshow(cm_)\n",
      "plt.title('Confusion matrix (per thousand)')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "plt.savefig('cm_rlm.png')\n",
      "\n",
      "print (time.time()-t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Arbre de d\u00e9cision"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import time\n",
      "import sklearn as sk\n",
      "#from sklearn.decomposition import PCA\n",
      "#from sklearn.feature_extraction import DictVectorizer\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "#from sklearn.tree import export_graphviz\n",
      "#from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score\n",
      "#from sklearn.cross_validation import train_test_split\n",
      "#from numpy import array\n",
      "import matplotlib.pyplot as plt\n",
      "import pickle\n",
      "from sklearn import grid_search"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curves = []\n",
      "for max_depth in range(10,20) :\n",
      "    clf = DecisionTreeClassifier(min_samples_leaf=5, max_depth=max_depth)\n",
      "    clf = clf.fit(train_set_x, train_set_y)\n",
      "    erra = accuracy_score( clf.predict(train_set_x), train_set_y)\n",
      "    errb = accuracy_score( clf.predict(test_set_x), test_set_y)\n",
      "    print(\"max_depth\",max_depth, \"erreur\",erra,errb)\n",
      "    curves.append((max_depth, erra,errb, clf) )\n",
      "plt.plot ( [c[0] for c in curves], [c[1] for c in curves], label=\"train\")\n",
      "plt.plot ( [c[0] for c in curves], [c[2] for c in curves], label=\"test\")\n",
      "plt.ylim( [0.8,1] )\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curves = []\n",
      "\n",
      "\n",
      "for min_samples_leaf in range(1,10) :\n",
      "    clf = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, max_depth=14)\n",
      "    clf = clf.fit(train_set_x, train_set_y)\n",
      "    erra = accuracy_score( clf.predict(train_set_x), train_set_y)\n",
      "    errb = accuracy_score( clf.predict(test_set_x), test_set_y)\n",
      "    print(\"min_samples_leaf\",min_samples_leaf, \"erreur\",erra,errb)\n",
      "    curves.append((min_samples_leaf, erra,errb, clf) )\n",
      "plt.plot ( [c[0] for c in curves], [c[1] for c in curves], label=\"train\")\n",
      "plt.plot ( [c[0] for c in curves], [c[2] for c in curves], label=\"test\")\n",
      "plt.ylim( [0.8,1] )\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "clf_ad = DecisionTreeClassifier(min_samples_leaf=5, max_depth=14)\n",
      "pred_set_y_ad = clf_ad.fit(train_set_x, train_set_y).predict(test_set_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "\n",
      "\n",
      "from sklearn.metrics import confusion_matrix\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "cm = confusion_matrix(test_set_y, pred_set_y_ad)\n",
      "\n",
      "print(cm)\n",
      "\n",
      "cm_ = np.zeros((10,10), dtype=np.float)\n",
      "for i in range (0, len(cm)):\n",
      "    sum_list = sum(cm[i])\n",
      "    for j in range (0, len(cm[i])) :\n",
      "        cm_[i][j] = (1.0 * cm[i][j]/ sum_list)*1000\n",
      "    \n",
      "print(cm_)\n",
      "    \n",
      "# Show confusion matrix in a separate window\n",
      "plt.matshow(cm_)\n",
      "plt.title('Confusion matrix (per thousand)')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "plt.savefig('cm_ad.png')\n",
      "\n",
      "print (time.time()-t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Comparaison des deux algos"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "delta = pred_set_y_rlm - pred_set_y_ad\n",
      "acc_ad = accuracy_score(clf_ad.predict(test_set_x), test_set_y)\n",
      "acc_rlm = accuracy_score(clf_rlm.predict(test_set_x), test_set_y)\n",
      "i= 0\n",
      "arr_delta = []\n",
      "for element in delta :\n",
      "    i+=1\n",
      "    if element != 0 :\n",
      "        arr_delta.append(i)\n",
      "print (len(arr_delta))\n",
      "\n",
      "best_ad = -10000+acc_ad*10000 + len(arr_delta)\n",
      "best_rlm = -10000+acc_rlm*10000 + len(arr_delta)\n",
      "best_comb = len(arr_delta)-best_ad-best_rlm\n",
      "print([acc_ad,best_ad], [acc_rlm,best_rlm], [(10000-best_comb)/10000,best_comb])\n",
      "#avec une bonne m\u00e9trique le max de perf : 93,38%"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "collapsed": true
     },
     "source": [
      "SVM (en cours)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import time\n",
      "t= time.time()\n",
      "\n",
      "print(t)\n",
      "import numpy as np\n",
      "#from sklearn import datasets\n",
      "from sklearn import svm\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn import linear_model\n",
      "import scipy\n",
      "a = -5\n",
      "b = 15\n",
      "C_possible_parameters = []\n",
      "gamma_possible_parameters = []\n",
      "puissance = np.linspace(a,b,11)\n",
      "for i in puissance:\n",
      "    C_possible_parameters.append(2^i)\n",
      "    gamma_possible_parameters.append(2^i)\n",
      "\n",
      "print(possible_parameters)\n",
      "\n",
      "\n",
      "\n",
      "clf_svm = grid_search.GridSearchCV(svm.SVC(C=1.0, kernel='rbf', \n",
      "                gamma=0.0, coef0=0.0, shrinking=True, probability=False,\n",
      "                tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
      "                max_iter=-1, random_state=None),\n",
      "    {'C': C_possible_parameters, 'gamma' : gamma_possible_parameters},\n",
      "    cv=3,\n",
      "    scoring='accuracy',\n",
      "    refit=True\n",
      ")\n",
      "\n",
      "print (time.time()-t) #min for one iteration #On the new server 308s\n",
      "clf_rlm.fit(train_set_x, train_set_y)\n",
      "\n",
      "\n",
      "print(\"meilleur estimateur : \", clf_svm.best_estimator_)\n",
      "print(\"meilleur parametre : \", clf_svm.best_params_)\n",
      "print(\"score : \", clf_svm.scorer_)\n",
      "print (\"final score: \", metrics.accuracy_score(test_set_y, clf_rlm.predict(test_set_x)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pred_set_y_rlm = clf_rlm.fit(train_set_x, train_set_y).predict(test_set_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "t = time.time()\n",
      "\n",
      "\n",
      "from sklearn.metrics import confusion_matrix\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "cm = confusion_matrix(test_set_y, pred_set_y_rlm)\n",
      "\n",
      "print(cm)\n",
      "\n",
      "cm_ = np.zeros((10,10), dtype=np.float)\n",
      "for i in range (0, len(cm)):\n",
      "    sum_list = sum(cm[i])\n",
      "    for j in range (0, len(cm[i])) :\n",
      "        cm_[i][j] = (1.0 * cm[i][j]/ sum_list)*1000\n",
      "    \n",
      "print(cm_)\n",
      "    \n",
      "# Show confusion matrix in a separate window\n",
      "plt.matshow(cm_)\n",
      "plt.title('Confusion matrix (per thousand)')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "\n",
      "print (time.time()-t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Random forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "curves = []\n",
      "for n_estimators in range(3,20) :\n",
      "    clf_rf = RandomForestClassifier(n_estimators=10*n_estimators,max_depth=14,min_samples_leaf=5)\n",
      "    clf_rf = clf_rf.fit(train_set_x, train_set_y)\n",
      "    erra = accuracy_score( clf_rf.predict(train_set_x), train_set_y)\n",
      "    errb = accuracy_score( clf_rf.predict(test_set_x), test_set_y)\n",
      "    print(\"n_estimators\",10*n_estimators, \"erreur\",erra,errb)\n",
      "    curves.append((10*n_estimators, erra,errb, clf_rf) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf_rf = RandomForestClassifier(n_estimators=80,max_depth=14,min_samples_leaf=5)\n",
      "pred_set_y_rf = clf_rf.fit(train_set_x, train_set_y).predict(test_set_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "cm = confusion_matrix(test_set_y, pred_set_y_rf)\n",
      "print(cm)\n",
      "\n",
      "cm_ = np.zeros((10,10), dtype=np.float)\n",
      "for i in range (0, len(cm)):\n",
      "    sum_list = sum(cm[i])\n",
      "    for j in range (0, len(cm[i])) :\n",
      "        cm_[i][j] = (1.0 * cm[i][j]/ sum_list)*1000\n",
      "    \n",
      "print(cm_)\n",
      "    \n",
      "# Show confusion matrix in a separate window\n",
      "plt.matshow(cm_)\n",
      "plt.title('Confusion matrix (per thousand)')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "plt.savefig('cm_rf.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "ROC curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import svm, datasets\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import label_binarize\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "\n",
      "'''\n",
      "sklearn.metrics.roc_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "y_true : array, shape = [n_samples]\n",
      "True binary labels in range {0, 1} or {-1, 1}. If labels are not binary, pos_label should be explicitly given.\n",
      "y_score : array, shape = [n_samples]\n",
      "Target scores, can either be probability estimates of the positive class or confidence values.\n",
      "pos_label : int\n",
      "Label considered as positive and others are considered negative.\n",
      "sample_weight : array-like of shape = [n_samples], optional\n",
      "Sample weights.'''\n",
      "\n",
      "# Compute ROC curve and ROC area for each class\n",
      "fpr = dict()\n",
      "tpr = dict()\n",
      "roc_auc = dict()\n",
      "for i in range(0,10):\n",
      "    fpr[i], tpr[i], _ = roc_curve(test_set_y, pred_set_y_rf, pos_label = i)\n",
      "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
      "    \n",
      "print (fpr[2],tpr[2])\n",
      "'''# Compute micro-average ROC curve and ROC area\n",
      "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_set_y.ravel(), pred_set_y_rf.ravel())\n",
      "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])'''\n",
      "\n",
      "# Plot of a ROC curve for a specific class\n",
      "plt.figure()\n",
      "plt.plot(fpr[2], tpr[2], label='ROC curve ' + str(roc_auc[2]))\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Random Forest ROC')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()\n",
      "\n",
      "'''#Plot ROC curve\n",
      "plt.figure()\n",
      "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
      "         label='micro-average ROC curve (area = {0:0.2f})'\n",
      "               ''.format(roc_auc[\"micro\"]))\n",
      "for i in range(n_classes):\n",
      "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
      "                                   ''.format(i, roc_auc[i]))\n",
      "\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Random Forest ROC')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()'''"
     ],
     "language": "python",
     "metadata": {
      "scrolled": false
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Learning curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.learning_curve import learning_curve\n",
      "\n",
      "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
      "                        n_jobs=1, train_sizes=np.linspace(.01, 1.0, 10)):\n",
      "    \"\"\"\n",
      "    Generate a simple plot of the test and traning learning curve.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
      "        An object of that type which is cloned for each validation.\n",
      "\n",
      "    title : string\n",
      "        Title for the chart.\n",
      "\n",
      "    X : array-like, shape (n_samples, n_features)\n",
      "        Training vector, where n_samples is the number of samples and\n",
      "        n_features is the number of features.\n",
      "\n",
      "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
      "        Target relative to X for classification or regression;\n",
      "        None for unsupervised learning.\n",
      "\n",
      "    ylim : tuple, shape (ymin, ymax), optional\n",
      "        Defines minimum and maximum yvalues plotted.\n",
      "\n",
      "    cv : integer, cross-validation generator, optional\n",
      "        If an integer is passed, it is the number of folds (defaults to 3).\n",
      "        Specific cross-validation objects can be passed, see\n",
      "        sklearn.cross_validation module for the list of possible objects\n",
      "\n",
      "    n_jobs : integer, optional\n",
      "        Number of jobs to run in parallel (default 1).\n",
      "    \"\"\"\n",
      "    plt.figure()\n",
      "    plt.title(title)\n",
      "    if ylim is not None:\n",
      "        plt.ylim(*ylim)\n",
      "    plt.xlabel(\"Training examples\")\n",
      "    plt.ylabel(\"Score\")\n",
      "    train_sizes, train_scores, test_scores = learning_curve(\n",
      "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
      "    train_scores_mean = np.mean(train_scores, axis=1)\n",
      "    train_scores_std = np.std(train_scores, axis=1)\n",
      "    test_scores_mean = np.mean(test_scores, axis=1)\n",
      "    test_scores_std = np.std(test_scores, axis=1)\n",
      "    plt.grid()\n",
      "\n",
      "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
      "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
      "                     color=\"r\")\n",
      "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
      "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
      "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
      "             label=\"Training score\")\n",
      "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
      "             label=\"Cross-validation score\")\n",
      "\n",
      "    plt.legend(loc=\"best\")\n",
      "    return plt\n",
      "\n",
      "\n",
      "title = \"Learning Curves (Random Forest)\"\n",
      "\n",
      "estimator = RandomForestClassifier(n_estimators=80,max_depth=14,min_samples_leaf=5)\n",
      "plot_learning_curve(estimator, title, train_set_x, train_set_y, ylim=None, cv=None, n_jobs=1)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "collapsed": false,
      "scrolled": true
     },
     "source": [
      "Validation Curves"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.learning_curve import validation_curve\n",
      "\n",
      "'''\n",
      "sklearn.learning_curve.validation_curve(estimator, X, y, param_name, param_range\n",
      ", cv=None, scoring=None, n_jobs=1, pre_dispatch='all', verbose=0)\n",
      "\n",
      "Parameters:\n",
      "estimator : object type that implements the \u201cfit\u201d and \u201cpredict\u201d methods\n",
      "An object of that type which is cloned for each validation.\n",
      "X : array-like, shape (n_samples, n_features)\n",
      "Training vector, where n_samples is the number of samples and n_features is the number of features.\n",
      "y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
      "Target relative to X for classification or regression; None for unsupervised learning.\n",
      "param_name : string\n",
      "Name of the parameter that will be varied.\n",
      "param_range : array-like, shape (n_values,)\n",
      "The values of the parameter that will be evaluated.\n",
      "cv : integer, cross-validation generator, optional\n",
      "If an integer is passed, it is the number of folds (defaults to 3). Specific cross-validation \n",
      "objects can be passed, see sklearn.cross_validation module for the list of possible objects\n",
      "scoring : string, callable or None, optional, default: None\n",
      "A string (see model evaluation documentation) or a scorer callable object / \n",
      "function with signature scorer(estimator, X, y).\n",
      "n_jobs : integer, optional\n",
      "Number of jobs to run in parallel (default 1).\n",
      "pre_dispatch : integer or string, optional\n",
      "Number of predispatched jobs for parallel execution (default is all). \n",
      "The option can reduce the allocated memory. The string can be an expression like \u20182*n_jobs\u2019.\n",
      "verbose : integer, optional\n",
      "Controls the verbosity: the higher, the more messages.'''\n",
      "\n",
      "\n",
      "def plot_validation_curve(estimator, title, param_name, param_range, X=train_set_x, y=train_set_y, \n",
      "                          ylim=None, cv=10, n_jobs=1):\n",
      "\n",
      "    plt.figure()\n",
      "    plt.title(title)\n",
      "    if ylim is not None:\n",
      "        plt.ylim(*ylim)\n",
      "    #plt.xlabel(param_name)\n",
      "    #plt.ylabel(\"Score\")\n",
      "    train_scores, valid_scores = validation_curve(estimator, X, y, \n",
      "                                              param_name, param_range, cv=cv)\n",
      "    #plt.plot(train_scores, param_range, 'o-', color=\"r\",label=\"Training\")  \n",
      "    #plt.plot(valid_scores, param_range, 'o-', color=\"r\",label=\"CV\")\n",
      "    #plt.legend(loc=\"best\")\n",
      "    #return plt\n",
      "    train_scores_mean = np.mean(train_scores, axis=1)\n",
      "    train_scores_std = np.std(train_scores, axis=1)\n",
      "    test_scores_mean = np.mean(valid_scores, axis=1)\n",
      "    test_scores_std = np.std(valid_scores, axis=1)\n",
      "\n",
      "    plt.xlabel(param_name)\n",
      "    plt.ylabel(\"Score\")\n",
      "    plt.ylim(0.0, 1.1)\n",
      "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
      "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
      "                     train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
      "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
      "                 color=\"g\")\n",
      "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
      "                     test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
      "    plt.legend(loc=\"best\")\n",
      "    return plt\n",
      "\n",
      "title = \"Validation Curves (Random Forest)\"\n",
      "\n",
      "estimator = RandomForestClassifier(n_estimators=80,min_samples_leaf=5)\n",
      "plot_validation_curve(estimator, title, 'max_depth', np.linspace(1, 200, 10, dtype = int))\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Les 5 confondus avec des 3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = clf_rf.predict(test_set_x)\n",
      "real = test_set\n",
      "i=0\n",
      "listoffive = []\n",
      "for number in real[1] :\n",
      "    if number == 5 :\n",
      "        listoffive.append(i)\n",
      "    i += 1\n",
      "\n",
      "errors = []\n",
      "for index in listoffive :\n",
      "    if predicted[index] != 5 :\n",
      "        errors.append([index,predicted[index]])\n",
      "print (errors)\n",
      "\n",
      "vect_images = []    \n",
      "for error in errors :\n",
      "    vect_images.append(test_set[0][error[0]])\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cmpkg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[0].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[7].reshape(28, 28), cmap = cmpkg.Greys_r)\n",
      "plt.savefig('img1.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[9].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[13].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[21].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[25].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[26].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[28].reshape(28, 28), cmap = cmpkg.Greys_r)\n",
      "plt.savefig('img2.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[30].reshape(28, 28), cmap = cmpkg.Greys_r)\n",
      "plt.savefig('img3.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[31].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[32].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[33].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[34].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[36].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(vect_images[37].reshape(28, 28), cmap = cmpkg.Greys_r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Restricted Boltzmann Machine (en cours)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import time\n",
      "t= time.time()\n",
      "\n",
      "print(t)\n",
      "import numpy as np\n",
      "\n",
      "from sklearn import svm\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn import linear_model\n",
      "import scipy\n",
      "from sklearn import neural_network\n",
      "\n",
      "neural_network.BernoulliRBM(n_components=256, \n",
      "                            learning_rate=0.1, \n",
      "                            batch_size=10, \n",
      "                            n_iter=10, \n",
      "                            verbose=0, \n",
      "                            random_state=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import time\n",
      "t= time.time()\n",
      "\n",
      "print(t)\n",
      "import numpy as np\n",
      "\n",
      "from sklearn import svm\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn import linear_model\n",
      "import scipy\n",
      "a = -5\n",
      "b = 1\n",
      "possible_parameters = []\n",
      "puissance = np.linspace(a,b,6)\n",
      "for i in puissance:\n",
      "    possible_parameters.append(2^i)\n",
      "\n",
      "clf_rbm = grid_search.GridSearchCV(svm.SVC(C=1.0, kernel='linear', degree=3, gamma=0.0, coef0=0.0, shrinking=True, \n",
      "                      probability=False, tol=0.001, cache_size=200, class_weight=None, \n",
      "                      verbose=False, max_iter=-1, random_state=None),\n",
      "    {'C': possible_parameters},\n",
      "    cv=3,\n",
      "    scoring='accuracy',\n",
      "    refit=True\n",
      ")\n",
      "\n",
      "print (time.time()-t) #min for one iteration #On the new server 308s\n",
      "clf_rbm.fit(train_set_x, train_set_y)\n",
      "\n",
      "\n",
      "print(\"meilleur estimateur : \", clf_svm.best_estimator_)\n",
      "print(\"meilleur parametre : \", clf_svm.best_params_)\n",
      "print(\"score : \", clf_svm.scorer_)\n",
      "print (\"final score: \", metrics.accuracy_score(test_set_y, clf_rlm.predict(test_set_x)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pred_set_y_rbm = clf_rbm.fit(train_set_x, train_set_y).predict(test_set_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "t = time.time()\n",
      "\n",
      "\n",
      "from sklearn.metrics import confusion_matrix\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "cm = confusion_matrix(test_set_y, pred_set_y_rlm)\n",
      "\n",
      "print(cm)\n",
      "\n",
      "cm_ = np.zeros((10,10), dtype=np.float)\n",
      "for i in range (0, len(cm)):\n",
      "    sum_list = sum(cm[i])\n",
      "    for j in range (0, len(cm[i])) :\n",
      "        cm_[i][j] = (1.0 * cm[i][j]/ sum_list)*1000\n",
      "    \n",
      "print(cm_)\n",
      "    \n",
      "# Show confusion matrix in a separate window\n",
      "plt.matshow(cm_)\n",
      "plt.title('Confusion matrix (per thousand)')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "plt.savefig('cm_rlm.png')\n",
      "\n",
      "print (time.time()-t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RBM + Logistic (\u00e0 param\u00e9trer)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "print(__doc__)\n",
      "\n",
      "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
      "# License: BSD\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from scipy.ndimage import convolve\n",
      "from sklearn import linear_model, datasets, metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "\n",
      "# Models we will use\n",
      "logistic = linear_model.LogisticRegression()\n",
      "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
      "\n",
      "clf_rbm = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
      "\n",
      "###############################################################################\n",
      "# Training\n",
      "\n",
      "# Hyper-parameters. These were set by cross-validation,\n",
      "# using a GridSearchCV. Here we are not performing cross-validation to\n",
      "# save time.\n",
      "rbm.learning_rate = 0.005\n",
      "rbm.n_iter = 20\n",
      "# More components tend to give better prediction performance, but larger\n",
      "# fitting time\n",
      "rbm.n_components = 100\n",
      "logistic.C = 6000.0\n",
      "\n",
      "\n",
      "print (time.time()-t) #min for one iteration #On the new server 308s\n",
      "clf_rbm.fit(train_set_x, train_set_y)\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "# Evaluation\n",
      "\n",
      "print()\n",
      "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        train_set_y,\n",
      "        clf_rbm.predict(train_set_x))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print()\n",
      "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        train_set_y,\n",
      "        clf_rbm.predict(train_set_x))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print()\n",
      "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        test_set_y,\n",
      "        clf_rbm.predict(test_set_x))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_set_y_rbm = clf_rbm.predict(test_set_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"final score: \", metrics.accuracy_score(test_set_y, clf_rbm.predict(test_set_x)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "cm = confusion_matrix(test_set_y, pred_set_y_rbm)\n",
      "print(cm)\n",
      "\n",
      "cm_ = np.zeros((10,10), dtype=np.float)\n",
      "for i in range (0, len(cm)):\n",
      "    sum_list = sum(cm[i])\n",
      "    for j in range (0, len(cm[i])) :\n",
      "        cm_[i][j] = (1.0 * cm[i][j]/ sum_list)*1000\n",
      "    \n",
      "print(cm_)\n",
      "    \n",
      "# Show confusion matrix in a separate window\n",
      "plt.matshow(cm_)\n",
      "plt.title('Confusion matrix (per thousand)')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "plt.savefig('cm_rf.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "print(__doc__)\n",
      "\n",
      "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
      "# License: BSD\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from scipy.ndimage import convolve\n",
      "from sklearn import linear_model, datasets, metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "from sklearn.pipeline import Pipeline\n",
      "import numpy as np\n",
      "\n",
      "# Models we will use\n",
      "logistic = linear_model.LogisticRegression()\n",
      "rbm = BernoulliRBM(n_components = 100, n_iter = 20, random_state=0, verbose=True)\n",
      "\n",
      "C_possible_parameters = np.linspace(7000,5000,2)\n",
      "rate_possible_parameters = np.linspace(0.07,0.05,2)\n",
      "\n",
      "clf_rbm_cv = grid_search.GridSearchCV(Pipeline(steps=[('rbm', rbm), ('logistic', logistic)]),\n",
      "    {'logistic__C': C_possible_parameters, 'rbm__learning_rate' : rate_possible_parameters},\n",
      "    cv=3,\n",
      "    scoring='accuracy',\n",
      "    refit=True\n",
      ")\n",
      "print(\"test\")\n",
      "###############################################################################\n",
      "# Training\n",
      "\n",
      "# Hyper-parameters. These were set by cross-validation,\n",
      "# using a GridSearchCV. Here we are not performing cross-validation to\n",
      "# save time.\n",
      "#rbm.learning_rate = 0.06\n",
      "\n",
      "# More components tend to give better prediction performance, but larger\n",
      "# fitting time\n",
      "\n",
      "#logistic.C = 6000.0\n",
      "\n",
      "\n",
      "print (time.time()-t) #min for one iteration #On the new server 308s\n",
      "clf_rbm_cv.fit(train_set_x, train_set_y)\n",
      "\n",
      "print(\"meilleur parametre : \", clf_rbm_cv.best_params_)\n",
      "print (\"final score: \", metrics.accuracy_score(test_set_y, clf_rbm_cv.predict(test_set_x)))\n",
      "\n",
      "###############################################################################\n",
      "# Evaluation\n",
      "\n",
      "print()\n",
      "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        test_set_y,\n",
      "        clf_rbm_cv.predict(test_set_x))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RBM + Linear SVC (\u00e0 faire)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "print(np.logspace(100,0,11))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RBM + Perceptron (\u00e0 faire)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Bonus : pif RBM + RF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "print(__doc__)\n",
      "\n",
      "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
      "# License: BSD\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from scipy.ndimage import convolve\n",
      "from sklearn import linear_model, datasets, metrics\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "    \n",
      "# Models we will use\n",
      "Forest = RandomForestClassifier(n_estimators=80,max_depth=14,min_samples_leaf=5)\n",
      "logistic = linear_model.LogisticRegression()\n",
      "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
      "\n",
      "clf_rbm_rf = Pipeline(steps=[('rbm', rbm), ('random forest', Forest)])\n",
      "\n",
      "###############################################################################\n",
      "# Training\n",
      "\n",
      "# Hyper-parameters. These were set by cross-validation,\n",
      "# using a GridSearchCV. Here we are not performing cross-validation to\n",
      "# save time.\n",
      "rbm.learning_rate = 0.06\n",
      "rbm.n_iter = 20\n",
      "# More components tend to give better prediction performance, but larger\n",
      "# fitting time\n",
      "rbm.n_components = 100\n",
      "Forest.n_estimators=80\n",
      "Forest.max_depth=14\n",
      "Forest.min_samples_leaf=5\n",
      "\n",
      "\n",
      "#print (time.time()-t) #min for one iteration #On the new server 308s\n",
      "clf_rbm_rf.fit(train_set_x, train_set_y)\n",
      "\n",
      "###############################################################################\n",
      "# Evaluation\n",
      "\n",
      "print()\n",
      "print(\"RF using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        train_set_y,\n",
      "        clf_rbm_rf.predict(train_set_x))))\n",
      "\n",
      "\n",
      "print()\n",
      "print(\"RF using RBM features:\\n%s\\n\" % (\n",
      "    metrics.classification_report(\n",
      "        test_set_y,\n",
      "        clf_rbm_rf.predict(test_set_x))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_set_y_rbm_rf = clf_rbm_rf.fit(train_set_x, train_set_y).predict(test_set_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (\"final score: \", metrics.accuracy_score(test_set_y, clf_rbm_rf.predict(test_set_x)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "cm = confusion_matrix(test_set_y, pred_set_y_rbm_rf)\n",
      "print(cm)\n",
      "\n",
      "cm_ = np.zeros((10,10), dtype=np.float)\n",
      "for i in range (0, len(cm)):\n",
      "    sum_list = sum(cm[i])\n",
      "    for j in range (0, len(cm[i])) :\n",
      "        cm_[i][j] = (1.0 * cm[i][j]/ sum_list)*1000\n",
      "    \n",
      "print(cm_)\n",
      "    \n",
      "# Show confusion matrix in a separate window\n",
      "plt.matshow(cm_)\n",
      "plt.title('Confusion matrix (per thousand)')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()\n",
      "plt.savefig('cm_rf.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature selection with L1 ? (pipeline)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}